# API de PrÃ©diction d'Attrition - Machine Learning

API FastAPI pour prÃ©dire l'attrition des employÃ©s Ã  l'aide d'un modÃ¨le de rÃ©gression logistique optimisÃ© avec Elastic Net.

## ğŸ“‹ Table des matiÃ¨res

- [Description](#description)
- [Architecture](#architecture)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [API Documentation](#api-documentation)
- [Tests](#tests)
- [DÃ©ploiement](#dÃ©ploiement)

## ğŸ¯ Description

Ce projet dÃ©ploie un modÃ¨le de machine learning (rÃ©gression logistique avec rÃ©gularisation Elastic Net) pour prÃ©dire l'attrition des employÃ©s. Le modÃ¨le a Ã©tÃ© entraÃ®nÃ© sur des donnÃ©es d'attrition d'entreprise et utilise PostgreSQL pour stocker les donnÃ©es et les prÃ©dictions.

### FonctionnalitÃ©s

- âœ… API REST avec FastAPI
- âœ… ModÃ¨le de rÃ©gression logistique avec Elastic Net
- âœ… Base de donnÃ©es PostgreSQL
- âœ… Enregistrement automatique des prÃ©dictions
- âœ… Documentation automatique (Swagger/OpenAPI)
- âœ… Tests unitaires avec pytest
- âœ… Docker et Docker Compose
- âœ… Pipeline CI/CD prÃªt

## ğŸ—ï¸ Architecture

```
docker_ml-fastapi/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # API FastAPI principale
â”‚   â”œâ”€â”€ model.py             # Chargement et utilisation du modÃ¨le
â”‚   â”œâ”€â”€ schemas.py           # SchÃ©mas Pydantic
â”‚   â”œâ”€â”€ settings.py          # Configuration
â”‚   â”œâ”€â”€ database.py          # Gestion PostgreSQL
â”‚   â”œâ”€â”€ train_model.py       # Script d'entraÃ®nement
â”‚   â”œâ”€â”€ load_data.py         # Chargement des donnÃ©es CSV â†’ PostgreSQL
â”‚   â””â”€â”€ requirements.txt     # DÃ©pendances Python
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ db.py                # Utilitaires SQLAlchemy
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 01_attrition.sql # Script SQL d'initialisation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py          # Tests unitaires
â”œâ”€â”€ models/                  # ModÃ¨les entraÃ®nÃ©s (gÃ©nÃ©rÃ©)
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸš€ Installation

### PrÃ©requis

- Docker et Docker Compose
- Python 3.11+ (pour dÃ©veloppement local)
- PostgreSQL 15+ (ou via Docker)

### Installation avec Docker (RecommandÃ©)

1. **Cloner le dÃ©pÃ´t**
```bash
git clone <votre-repo>
cd docker_ml-fastapi
```

2. **CrÃ©er un fichier `.env`** (optionnel)
```bash
DATABASE_URL=postgresql://postgres:password@db:5432/mydatabase
MODEL_VERSION=1.0.0
```

3. **Construire et dÃ©marrer les conteneurs**
```bash
docker-compose up --build
```

L'API sera accessible sur `http://localhost:8090`

### Installation locale (DÃ©veloppement)

1. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

2. **Installer les dÃ©pendances**
```bash
pip install -r app/requirements.txt
```

3. **Configurer PostgreSQL**
   - CrÃ©er une base de donnÃ©es `mydatabase`
   - ExÃ©cuter le script `db/init/01_attrition.sql`

4. **Charger les donnÃ©es** (si vous avez les CSV)
```bash
export DATABASE_URL="postgresql://postgres:password@localhost:5432/mydatabase"
python app/load_data.py
```

5. **EntraÃ®ner le modÃ¨le**
```bash
python app/train_model.py
```

6. **DÃ©marrer l'API**
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8090
```

## ğŸ“– Utilisation

### 1. Charger les donnÃ©es dans PostgreSQL

Si vous avez les fichiers CSV (`extrait_sirh.csv`, `extrait_eval.csv`, `extrait_sondage.csv`), placez-les dans un dossier `data/` et exÃ©cutez :

```bash
python app/load_data.py
```

### 2. EntraÃ®ner le modÃ¨le

```bash
python app/train_model.py
```

Le script va :
- Charger les donnÃ©es depuis PostgreSQL
- PrÃ©parer les features (encodage, variables calculÃ©es)
- EntraÃ®ner un modÃ¨le de rÃ©gression logistique avec Elastic Net
- Optimiser les hyperparamÃ¨tres avec GridSearchCV
- Sauvegarder le modÃ¨le dans `models/`

### 3. Utiliser l'API

#### Documentation interactive

AccÃ©dez Ã  la documentation Swagger :
```
http://localhost:8090/docs
```

#### Exemple de prÃ©diction

```bash
curl -X POST "http://localhost:8090/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "employee_data": {
      "age": 35,
      "genre": "M",
      "revenu_mensuel": 5000,
      "statut_marital": "MariÃ©(e)",
      "departement": "R&D",
      "poste": "Data Scientist",
      "nombre_experiences_precedentes": 3,
      "annee_experience_totale": 8,
      "annees_dans_l_entreprise": 5,
      "annees_dans_le_poste_actuel": 2,
      "satisfaction_employee_environnement": 4,
      "note_evaluation_precedente": 4.0,
      "niveau_hierarchique_poste": 2,
      "satisfaction_employee_nature_travail": 4,
      "satisfaction_employee_equipe": 4,
      "satisfaction_employee_equilibre_pro_perso": 3,
      "note_evaluation_actuelle": 4.5,
      "heure_supplementaires": "Non",
      "nombre_participation_pee": 2,
      "nb_formations_suivies": 3,
      "distance_domicile_travail": 10,
      "niveau_education": 3,
      "domaine_etude": "Data Science",
      "frequence_deplacement": "Occasionnel",
      "annees_depuis_la_derniere_promotion": 2,
      "annes_sous_responsable_actuel": 1,
      "augmentation_salaire_precedente": 0.05
    }
  }'
```

## ğŸ“š API Documentation

### Endpoints

#### `GET /health`
VÃ©rifie l'Ã©tat de l'API, du modÃ¨le et de la base de donnÃ©es.

**RÃ©ponse:**
```json
{
  "status": "ok",
  "model_loaded": true,
  "db_connected": true
}
```

#### `POST /predict`
PrÃ©dit l'attrition pour un employÃ©.

**Body:**
```json
{
  "employee_data": {
    "age": 35,
    "genre": "M",
    ...
  }
}
```

**RÃ©ponse:**
```json
{
  "prediction": 0,
  "probability": 0.2345,
  "model_version": "1.0.0",
  "prediction_id": 123
}
```

#### `GET /predictions`
RÃ©cupÃ¨re les derniÃ¨res prÃ©dictions enregistrÃ©es.

**ParamÃ¨tres:**
- `limit` (optionnel): Nombre de prÃ©dictions Ã  retourner (dÃ©faut: 100)

#### `GET /db-test`
Teste la connexion Ã  la base de donnÃ©es.

## ğŸ§ª Tests

### ExÃ©cuter les tests

```bash
pytest tests/ -v
```

### Avec couverture de code

```bash
pytest tests/ --cov=app --cov-report=html
```

Les rapports de couverture seront gÃ©nÃ©rÃ©s dans `htmlcov/`.

## ğŸ³ DÃ©ploiement

### Docker Compose

Le fichier `docker-compose.yml` configure :
- **API FastAPI** sur le port 8090
- **PostgreSQL** sur le port 5432

### Variables d'environnement

- `DATABASE_URL`: URL de connexion PostgreSQL
- `MODEL_VERSION`: Version du modÃ¨le (dÃ©faut: 1.0.0)

### DÃ©ploiement sur Render.com

1. Connecter votre dÃ©pÃ´t Git Ã  Render
2. Configurer les variables d'environnement
3. DÃ©ployer avec le Dockerfile fourni

## ğŸ”§ ModÃ¨le de Machine Learning

### CaractÃ©ristiques

- **Algorithme**: RÃ©gression logistique avec rÃ©gularisation Elastic Net
- **Optimisation**: GridSearchCV avec validation croisÃ©e (5 folds)
- **MÃ©triques**: ROC-AUC, AUC-PR, F1-score
- **Features**: 39 variables aprÃ¨s encodage et crÃ©ation de variables calculÃ©es

### Variables calculÃ©es

- `ratio_anciennete`: AnciennetÃ© / ExpÃ©rience totale
- `ratio_poste`: AnnÃ©es dans le poste / AnnÃ©es dans l'entreprise
- `ecart_evaluation`: DiffÃ©rence entre Ã©valuations
- `ratio_salaire_niveau`: Salaire / Niveau hiÃ©rarchique
- `ratio_formations`: Formations / AnciennetÃ©
- `indice_recente_promo`: Indice de rÃ©cence de promotion

## ğŸ“ Structure de la base de donnÃ©es

### Tables

- **sirh**: DonnÃ©es RH des employÃ©s
- **performance**: Ã‰valuations de performance
- **sondage**: DonnÃ©es de sondage bien-Ãªtre
- **predictions**: Enregistrement des prÃ©dictions (inputs/outputs)

## ğŸ¤ Contribution

1. CrÃ©er une branche (`git checkout -b feature/amÃ©lioration`)
2. Commit les changements (`git commit -m 'Ajout d'une fonctionnalitÃ©'`)
3. Push vers la branche (`git push origin feature/amÃ©lioration`)
4. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est un projet de formation OpenClassrooms.

## ğŸ‘¤ Auteur

Gregory Crespin - Projet 4 - DÃ©ploiement d'un modÃ¨le ML

---

**Note**: Ce projet nÃ©cessite que le modÃ¨le soit entraÃ®nÃ© avant de pouvoir faire des prÃ©dictions. ExÃ©cutez `python app/train_model.py` aprÃ¨s avoir chargÃ© les donnÃ©es dans PostgreSQL.
